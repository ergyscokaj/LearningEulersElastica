{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6J10IbrFs3OT"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "# !pip install optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd.functional import jacobian as jac\n",
    "from torch.func import jacfwd, vmap\n",
    "from csv import writer\n",
    "import os\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "STfDbJumK3Xb"
   },
   "outputs": [],
   "source": [
    "# if running with Google Colab, enter the right path from your Drive\n",
    "# otherwise completely comment this cell\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd \"/content/drive/Othercomputers/My MacBook Pro (1)/LearningEulersElastica/ContinuousNetwork\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6049,
     "status": "ok",
     "timestamp": 1701767172515,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "D2_OcS7oKWO1"
   },
   "outputs": [],
   "source": [
    "from Scripts.GetData import getDataLoaders, loadData\n",
    "from Scripts.Utils import getBCs\n",
    "from Scripts.Network import approximate_curve\n",
    "# from Scripts.Training import trainModel\n",
    "from Scripts.PlotResults import plotTestResults\n",
    "from Scripts.SavedParameters import hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1701767172516,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "BZSovV7Wczb4"
   },
   "outputs": [],
   "source": [
    "#We do this so Pytorch works in double precision\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1701767172516,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "XJQy9f1dMtjT",
    "outputId": "22e9f75f-ede7-486a-d029-3ea77e9596a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701767172516,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "AfIV2h2voANF"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3900,
     "status": "ok",
     "timestamp": 1701767176411,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "hf5os7a9g6Kj",
    "outputId": "f0a61789-a2b4-4e6d-9ef9-e28febf3d9e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose percentage of training data between 90, 40, 20, and 10: 80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_train = input(\"Choose percentage of training data between 90, 40, 20, and 10: \")\n",
    "percentage_train = int(percentage_train)/100\n",
    "percentage_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trainModel(number_elements,device,model,criterion,optimizer,epochs,trainloader,train_with_tangents=False,pde_regularisation=True,soft_bcs_imposition=False):\n",
    "  \n",
    "#   torch.manual_seed(1)\n",
    "#   np.random.seed(1)\n",
    "  \n",
    "#   lossVal = 1.\n",
    "#   epoch = 1\n",
    "#   scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=45, gamma=0.1)\n",
    "#   x_eval = np.linspace(0,1,number_elements+1)\n",
    "    \n",
    "#   stored_res = 0\n",
    "#   count = 0\n",
    "#   cc = 0\n",
    "#   is_good_loss = False\n",
    "  \n",
    "#   while epoch < epochs:\n",
    "#       losses = []\n",
    "#       running_loss = 0\n",
    "\n",
    "#       for i, inp in enumerate(trainloader):\n",
    "#           q1,q2,v1,v2,s,_,qs,vs = inp\n",
    "#           q1,q2,v1,v2,s,qs,vs = q1.to(device),q2.to(device),v1.to(device),v2.to(device),s.to(device),qs.to(device),vs.to(device)\n",
    "\n",
    "#           def closure():\n",
    "#               optimizer.zero_grad()\n",
    "#               res_q = model(s,q1,q2,v1,v2)\n",
    "#               loss = criterion(res_q,qs) + criterion(model.derivative(s,q1,q2,v1,v2),vs) #Comparison only of the qs\n",
    "#               loss += 1e-2 * torch.mean((torch.linalg.norm(model.derivative(s, q1, q2, v1, v2), ord=2, dim=1)**2-1.)**2)           \n",
    "#               loss.backward()\n",
    "#               return loss\n",
    "            \n",
    "#           optimizer.step(closure)\n",
    "#       model.eval();\n",
    "    \n",
    "#       with torch.no_grad():\n",
    "#         res_q = model(s,q1,q2,v1,v2)\n",
    "#         loss = criterion(res_q,qs)\n",
    "#         is_good_loss = (loss.item()<8e-6)\n",
    "#         if epoch == 1:\n",
    "#           stored_res = loss.item()\n",
    "#         if epoch == 30:\n",
    "#           check = (loss.item()>(stored_res * 1e-1))\n",
    "#           if check and stored_res>1e-2:\n",
    "#             print(\"Early stop due to lack of progress\")\n",
    "#             loss = torch.tensor(torch.nan)\n",
    "#             epoch = epochs + 10\n",
    "#         print(f'Loss [{epoch+1}](epoch): ', loss.item())\n",
    "#         if torch.isnan(loss):\n",
    "#           epoch = epochs + 10\n",
    "#           break\n",
    "            \n",
    "#       model.train();\n",
    "#       epoch += 1\n",
    "#       scheduler.step()\n",
    "\n",
    "#   print('Training Done')\n",
    "#   print(\"Loss : \",loss.item())\n",
    "#   return loss\n",
    "\n",
    "\n",
    "def trainModel(number_elements,device,model,criterion,optimizer,epochs,trainloader,valloader,train_with_tangents=False,pde_regularisation=True,soft_bcs_imposition=False):\n",
    "  \n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    lossVal = 1.\n",
    "    epoch = 1\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=45, gamma=0.1)\n",
    "    x_eval = np.linspace(0,1,number_elements+1)\n",
    "\n",
    "    stored_res = 0\n",
    "    count = 0\n",
    "    cc = 0\n",
    "    is_good_loss = False\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    while epoch <= epochs:\n",
    "        losses = []\n",
    "        running_loss = 0\n",
    "\n",
    "        for i, inp in enumerate(trainloader):\n",
    "            q1,q2,v1,v2,s,_,qs,vs = inp\n",
    "            q1,q2,v1,v2,s,qs,vs = q1.to(device),q2.to(device),v1.to(device),v2.to(device),s.to(device),qs.to(device),vs.to(device)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            res_q = model(s,q1,q2,v1,v2)\n",
    "            loss = criterion(res_q,qs) + criterion(model.derivative(s,q1,q2,v1,v2),vs) #Comparison only of the qs\n",
    "            loss += 1e-2 * torch.mean((torch.linalg.norm(model.derivative(s, q1, q2, v1, v2), ord=2, dim=1)**2-1.)**2)           \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calculate average training loss\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "        train_losses.append(train_loss_avg)\n",
    "        \n",
    "        model.eval();\n",
    "        \n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inp in valloader:\n",
    "                q1_val, q2_val, v1_val, v2_val, s_val, _, qs_val, vs_val = inp\n",
    "                q1_val, q2_val, v1_val, v2_val, s_val, qs_val, vs_val = q1_val.to(device), q2_val.to(device), v1_val.to(device), v2_val.to(device), s_val.to(device), qs_val.to(device), vs_val.to(device)\n",
    "\n",
    "                res_q_val = model(s_val, q1_val, q2_val, v1_val, v2_val)\n",
    "                val_loss += criterion(res_q_val, qs_val).item()\n",
    "\n",
    "            # Calculate average validation loss\n",
    "            val_loss_avg = val_loss / len(valloader)\n",
    "            val_losses.append(val_loss_avg)\n",
    "\n",
    "            # Print training and validation losses for each epoch\n",
    "            print(f\"The average loss in epoch {epoch+1} is \",train_loss_avg)            \n",
    "\n",
    "    #         res_q = model(s,q1,q2,v1,v2)\n",
    "    #         loss = criterion(res_q,qs)\n",
    "\n",
    "            is_good_loss = (loss.item()<8e-6)\n",
    "            if epoch == 1:\n",
    "                stored_res = loss.item()\n",
    "            if epoch == 30:\n",
    "                check = (loss.item()>(stored_res * 1e-1))\n",
    "                if check and stored_res>1e-2:\n",
    "                    print(\"Early stop due to lack of progress\")\n",
    "                    loss = torch.tensor(torch.nan)\n",
    "                    epoch = epochs + 10\n",
    "#             print(f'Loss [{epoch+1}](epoch): ', loss.item())\n",
    "            if torch.isnan(loss):\n",
    "                epoch = epochs + 10\n",
    "                break\n",
    "\n",
    "        model.train();\n",
    "        epoch += 1\n",
    "        scheduler.step()\n",
    "\n",
    "    print('Training Done')\n",
    "      \n",
    "    plt.semilogy(np.arange(epochs), train_losses,'r-*',label=\"training loss\",markersize=1)\n",
    "    plt.semilogy(np.arange(epochs), val_losses,'k-d',label=\"validation loss\",markersize=1)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss value\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Training and validation losses\")\n",
    "    plt.show();\n",
    "\n",
    "#     print(\"Loss : \",loss.item())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2325,
     "status": "ok",
     "timestamp": 1701767178732,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "VwE3w5ONQbPn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (789, 8)\n",
      "val :  (98, 8)\n",
      "test :  (98, 8)\n"
     ]
    }
   ],
   "source": [
    "num_nodes, trajectories_train, test_traj = loadData()\n",
    "shuffle_idx_train = np.random.permutation(len(trajectories_train))\n",
    "trajectories_train = trajectories_train[shuffle_idx_train]\n",
    "test_traj = test_traj[shuffle_idx_train]\n",
    "\n",
    "number_samples_train, number_components = trajectories_train.shape\n",
    "indices_train = np.random.permutation(len(trajectories_train))\n",
    "trajectories_train = trajectories_train[indices_train]\n",
    "number_samples_test, _ = test_traj.shape\n",
    "test_traj = test_traj[indices_train]\n",
    "\n",
    "number_elements = int(number_components/4)-1\n",
    "data_train, data_test, data_val, x_train, x_test, y_train, y_test, x_val, y_val, trainloader, testloader, valloader = getDataLoaders(batch_size, number_elements,number_samples_train, number_samples_test,trajectories_train, test_traj, percentage_train)\n",
    "\n",
    "training_trajectories = np.concatenate((x_train[:,:4],y_train,x_train[:,-4:]),axis=1)\n",
    "test_trajectories = np.concatenate((x_test[:,:4],y_test,x_test[:,-4:]),axis=1)\n",
    "val_trajectories = np.concatenate((x_val[:,:4],y_val,x_val[:,-4:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1701767178733,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "ZmhHT3cMULbB"
   },
   "outputs": [],
   "source": [
    "# def define_model(trial):\n",
    "\n",
    "#     torch.manual_seed(1)\n",
    "#     np.random.seed(1)\n",
    "\n",
    "#     normalize = trial.suggest_categorical(\"normalize\",[True,False])\n",
    "#     netarch = trial.suggest_categorical(\"networkarch\",[0,1,2])\n",
    "    \n",
    "#     if netarch == 0:\n",
    "#       is_mult = True\n",
    "#       is_res = False\n",
    "#     elif netarch == 1:\n",
    "#       is_mult = False\n",
    "#       is_res = True\n",
    "#     else:\n",
    "#       is_mult = False\n",
    "#       is_res = False\n",
    "#     act = trial.suggest_categorical(\"act\",['tanh','sigmoid','sin','swish'])\n",
    "#     nlayers = trial.suggest_int(\"n_layers\", 3, 8)\n",
    "#     hidden_nodes = trial.suggest_int(\"hidden_nodes\", 10, 200)\n",
    "#     model = approximate_curve(normalize, act, nlayers, hidden_nodes, correct_functional=False, is_res=is_res, is_mult=is_mult, both=False)\n",
    "#     return model\n",
    "\n",
    "def define_model(trial):\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    normalize = True\n",
    "    netarch = 0\n",
    "    \n",
    "    if netarch == 0:\n",
    "      is_mult = True\n",
    "      is_res = False\n",
    "    elif netarch == 1:\n",
    "      is_mult = False\n",
    "      is_res = True\n",
    "    else:\n",
    "      is_mult = False\n",
    "      is_res = False\n",
    "    act = 'tanh'\n",
    "    nlayers = trial.suggest_int(\"n_layers\", 3, 8)\n",
    "    hidden_nodes = trial.suggest_int(\"hidden_nodes\", 10, 200)\n",
    "    model = approximate_curve(normalize, act, nlayers, hidden_nodes, correct_functional=False, is_res=is_res, is_mult=is_mult, both=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1701767178733,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "2BiSKcFDQbPo"
   },
   "outputs": [],
   "source": [
    "# batch_size = 1024\n",
    "# epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1701767178734,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "8VNduZVhQbPo"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def flatten_chain(matrix):\n",
    "    return list(chain.from_iterable(matrix))\n",
    "\n",
    "q_idx = flatten_chain([[i,i+1] for i in np.arange(0,number_components,4)]) #indices of the qs\n",
    "qp_idx = flatten_chain([[i+2,i+3] for i in np.arange(0,number_components,4)]) #indices of the q's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1701767178734,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "1QNrylGbURvx"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    model = define_model(trial)\n",
    "    model.to(device);\n",
    "\n",
    "#     lr = trial.suggest_float(\"lr\", 1e-3 , 1e-1, log=True)\n",
    "    lr = 1e-3\n",
    "    weight_decay = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    _, _, _, _, _, _, _, _, _, trainloader, testloader, valloader = getDataLoaders(batch_size, number_elements,number_samples_train, number_samples_test,trajectories_train, test_traj, percentage_train)\n",
    "\n",
    "    print(\"Current test with :\\n\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "      print(\"    {}: {}\".format(key, value))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    loss = trainModel(number_elements,device,model,criterion,optimizer,epochs,trainloader,valloader,train_with_tangents=False,pde_regularisation=False,soft_bcs_imposition=False)\n",
    "    val_error = 100\n",
    "    if not torch.isnan(loss):\n",
    "        model.eval();\n",
    "\n",
    "        def eval_model(model,device,s,q1,q2,v1,v2):\n",
    "            s_ = torch.tensor([[s]],dtype=torch.float32).to(device)\n",
    "            q1 = torch.from_numpy(q1.astype(np.float32)).reshape(1,-1).to(device)\n",
    "            q2 = torch.from_numpy(q2.astype(np.float32)).reshape(1,-1).to(device)\n",
    "            v1 = torch.from_numpy(v1.astype(np.float32)).reshape(1,-1).to(device)\n",
    "            v2 = torch.from_numpy(v2.astype(np.float32)).reshape(1,-1).to(device)\n",
    "            return model(s_,q1,q2,v1,v2).detach().cpu().numpy()[0]\n",
    "\n",
    "        def eval_derivative_model(model,device,s,q1,q2,v1,v2):\n",
    "            s_ = torch.tensor([[s]],dtype=torch.float32).to(device)\n",
    "            q1 = torch.from_numpy(q1.astype(np.float32)).reshape(1,-1).to(device)\n",
    "            q2 = torch.from_numpy(q2.astype(np.float32)).reshape(1,-1).to(device)\n",
    "            v1 = torch.from_numpy(v1.astype(np.float32)).reshape(1,-1).to(device)\n",
    "            v2 = torch.from_numpy(v2.astype(np.float32)).reshape(1,-1).to(device)\n",
    "\n",
    "            return model.derivative(s_,q1,q2,v1,v2).detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "        bcs = getBCs(val_trajectories)\n",
    "        q1 = bcs[\"q1\"]\n",
    "        q2 = bcs[\"q2\"]\n",
    "        v1 = bcs[\"v1\"]\n",
    "        v2 = bcs[\"v2\"]\n",
    "\n",
    "        q1 = torch.from_numpy(bcs[\"q1\"].astype(np.float32)).to(device)\n",
    "        q2 = torch.from_numpy(bcs[\"q2\"].astype(np.float32)).to(device)\n",
    "        v1 = torch.from_numpy(bcs[\"v1\"].astype(np.float32)).to(device)\n",
    "        v2 = torch.from_numpy(bcs[\"v2\"].astype(np.float32)).to(device)\n",
    "\n",
    "        q_idx = flatten_chain([[i,i+1] for i in np.arange(0,number_components,4)]) #indices of the qs\n",
    "        qp_idx = flatten_chain([[i+2,i+3] for i in np.arange(0,number_components,4)]) #indices of the q's\n",
    "\n",
    "        xx = torch.linspace(0,1,number_elements+1).unsqueeze(1).repeat(len(q1),1).to(device)\n",
    "        one = torch.ones((number_elements+1,1)).to(device)\n",
    "        q1_augmented = torch.kron(q1,one)\n",
    "        q2_augmented = torch.kron(q2,one)\n",
    "        v1_augmented = torch.kron(v1,one)\n",
    "        v2_augmented = torch.kron(v2,one)\n",
    "\n",
    "        pred_val_q = model(xx,q1_augmented,q2_augmented,v1_augmented,v2_augmented).reshape(len(q1),-1).detach().cpu().numpy()\n",
    "        val_error_q = np.mean((pred_val_q-val_trajectories[:,q_idx])**2)\n",
    "        pred_val_qp = model.derivative(xx,q1_augmented,q2_augmented,v1_augmented,v2_augmented).reshape(len(q1),-1).detach().cpu().numpy()\n",
    "        val_error_qp = np.mean((pred_val_qp-val_trajectories[:,qp_idx])**2)\n",
    "        pred_val_all = np.zeros_like(val_trajectories)\n",
    "        pred_val_all[:, q_idx] = pred_val_q\n",
    "        pred_val_all[:, qp_idx] = pred_val_qp\n",
    "        val_error = np.mean((pred_val_all-val_trajectories)**2)\n",
    "\n",
    "    #Saving the obtained results\n",
    "    if trial.number == 0:\n",
    "        labels = []\n",
    "        for lab, _ in trial.params.items():\n",
    "            labels.append(str(lab))\n",
    "        labels.append(\"Test error\")\n",
    "        with open(\"SavedResults.csv\", \"a\") as f_object:\n",
    "            writer_object = writer(f_object)\n",
    "            writer_object.writerow(labels)\n",
    "            writer_object.writerow(f\"\\n\\n Percentage of training data: {percentage_train}\")\n",
    "            f_object.close()\n",
    "\n",
    "    results = []\n",
    "    for _, value in trial.params.items():\n",
    "        results.append(str(value))\n",
    "\n",
    "    results.append(val_error)\n",
    "\n",
    "    with open(\"SavedResults.csv\", \"a\") as f_object:\n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow(results)\n",
    "        f_object.close()\n",
    "\n",
    "    return val_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2246,
     "status": "ok",
     "timestamp": 1701767180972,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "mZdWqmBOWfng",
    "outputId": "11cebb90-b253-497f-9976-9f16ec0eda66",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to do hyperparameter test? Type yes or no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-27 17:31:36,764] A new study created in memory with name: Euler Elastica\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (789, 8)\n",
      "val :  (98, 8)\n",
      "test :  (98, 8)\n",
      "Current test with :\n",
      "\n",
      "\n",
      "    n_layers: 6\n",
      "    hidden_nodes: 67\n",
      "\n",
      "\n",
      "\n",
      "The average loss in epoch 2 is  0.7325676673402389\n",
      "The average loss in epoch 3 is  0.10463003410647313\n",
      "The average loss in epoch 4 is  0.06299862591549754\n",
      "The average loss in epoch 5 is  0.050413794039438166\n",
      "The average loss in epoch 6 is  0.03991327085532248\n"
     ]
    }
   ],
   "source": [
    "optuna_study = input(\"Do you want to do hyperparameter test? Type yes or no \")\n",
    "params = {}\n",
    "if optuna_study==\"yes\":\n",
    "    optuna_study = True\n",
    "else:\n",
    "    optuna_study = False\n",
    "if optuna_study:\n",
    "    study = optuna.create_study(direction=\"minimize\",study_name=\"Euler Elastica\")\n",
    "    study.optimize(objective, n_trials=300)\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params\n",
    "params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1701767180973,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "drQgvqbBQbPp"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701767180973,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "pG72GxBPJ9Af"
   },
   "outputs": [],
   "source": [
    "manual_input = False\n",
    "if params=={}:\n",
    "    # We can input them manually by uncommenting the lines below\n",
    "    if manual_input:\n",
    "        print(\"No parameters have been specified. Let's input them:\\n\\n\")\n",
    "        normalize = input(\"Normalize is True or False? \")==\"True\"\n",
    "        networkarch = int(input(\"Network architecture: Type 0 for MULT, 1 for ResNet, 2 for MLP: \"))\n",
    "        act = input(\"What activation function to use? Choose among 'sin', 'sigmoid', 'swish', 'tanh': \")\n",
    "        nlayers = int(input(\"How many layers do you want the network to have? \"))\n",
    "        hidden_nodes = int(input(\"How many hidden nodes do you want the network to have? \"))\n",
    "        lr = float(input(\"What learning rate do you want to use? \"))\n",
    "        params = {\"normalize\": normalize,\n",
    "                \"act\": act,\n",
    "                \"n_layers\":nlayers,\n",
    "                \"hidden_nodes\":hidden_nodes,\n",
    "                \"networkarch\":networkarch,\n",
    "                \"lr\":lr}\n",
    "    else:\n",
    "    # or we can use the combinations found by Optuna that yield the best results for the mentioned datacases\n",
    "        params = hyperparams(percentage_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701767180973,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "nPGWqwFoI_4u",
    "outputId": "4ba0f733-9b2a-45f9-a9f2-0c4c12a4770e"
   },
   "outputs": [],
   "source": [
    "print(f'The hyperparameters yelding the best results for this case are: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701767180974,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "cwcBoE2dJ9Ag"
   },
   "outputs": [],
   "source": [
    "def define_best_model():\n",
    "    normalize = True #params[\"normalize\"]\n",
    "    act = 'tanh'#params[\"act\"]\n",
    "    nlayers = params[\"n_layers\"]\n",
    "    hidden_nodes = params[\"hidden_nodes\"]\n",
    "\n",
    "#     if params[\"networkarch\"] == 0:\n",
    "#         is_mult = True\n",
    "#         is_res = False\n",
    "#     elif params[\"networkarch\"] == 1:\n",
    "#        is_mult = False\n",
    "#        is_res = True\n",
    "#     else:\n",
    "#         is_mult = False\n",
    "#         is_res = False\n",
    "\n",
    "    is_mult = True\n",
    "    is_res = False\n",
    "    model = approximate_curve(normalize, act, nlayers, hidden_nodes, correct_functional=False, is_res=is_res, is_mult=is_mult, both=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6213,
     "status": "ok",
     "timestamp": 1701767187181,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "iimUr0a1J9Ag"
   },
   "outputs": [],
   "source": [
    "model = define_best_model()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1757,
     "status": "ok",
     "timestamp": 1701767188911,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "0YCc_GQAg6Kn",
    "outputId": "5575b65c-e6c6-4669-ea97-8dac2a9e04ca"
   },
   "outputs": [],
   "source": [
    "TrainMode = input(\"Train Mode True or False? Type 0 for False and 1 for True: \")\n",
    "TrainMode = int(TrainMode)\n",
    "if TrainMode == 0:\n",
    "    TrainMode = False\n",
    "else:\n",
    "    TrainMode = True\n",
    "TrainMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2100,
     "status": "ok",
     "timestamp": 1701767191008,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "4fc13QozJ9Ah",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_decay = 0\n",
    "lr = 1e-3 #params[\"lr\"]\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "_, _, _, _, _, _, _, _, _, trainloader, testloader, valloader = getDataLoaders(batch_size, number_elements,number_samples_train, number_samples_test,trajectories_train, test_traj, percentage_train)\n",
    "model.to(device);\n",
    "\n",
    "if TrainMode:\n",
    "    loss = trainModel(number_elements,device,model,criterion,optimizer,epochs,trainloader,valloader, train_with_tangents=False,pde_regularisation=False,soft_bcs_imposition=False)\n",
    "    if percentage_train == 0.9:\n",
    "        torch.save(model.state_dict(), 'TrainedModels/BothEnds0.9data.pt')\n",
    "    elif percentage_train == 0.4:\n",
    "        torch.save(model.state_dict(), 'TrainedModels/BothEnds0.4data.pt')\n",
    "    elif percentage_train == 0.2:\n",
    "        torch.save(model.state_dict(), 'TrainedModels/BothEnds0.2data.pt')\n",
    "    else:\n",
    "        torch.save(model.state_dict(), 'TrainedModels/BothEnds0.1data.pt')\n",
    "else:\n",
    "    if percentage_train == 0.9:\n",
    "        pretrained_dict = torch.load(f'TrainedModels/BothEnds0.9data.pt',map_location=device)\n",
    "    elif percentage_train == 0.4:\n",
    "        pretrained_dict = torch.load(f'TrainedModels/BothEnds0.4data.pt',map_location=device)\n",
    "    elif percentage_train == 0.2:\n",
    "        pretrained_dict = torch.load(f'TrainedModels/BothEnds0.2data.pt',map_location=device)\n",
    "    else:\n",
    "        pretrained_dict = torch.load(f'TrainedModels/BothEnds0.1data.pt',map_location=device)\n",
    "    model.load_state_dict(pretrained_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5289,
     "status": "ok",
     "timestamp": 1701767363603,
     "user": {
      "displayName": "Ergys Çokaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "QOLxtnER5vQH",
    "outputId": "a6de24bd-909c-4b55-a677-3cc395260d5a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# printing the accuracies and plotting the results\n",
    "\n",
    "model.eval();\n",
    "res,res_derivative = plotTestResults(model,device,number_elements,number_components,x_train,x_test,y_train,y_test, num_nodes, percentage_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed7ab7e2e8a9240e70ddeb3e0a5d2646d3f0c1850e1b729c718218fffe2c99a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
