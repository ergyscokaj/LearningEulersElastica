{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZmJ-_zvokaO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#importing necessary packages\n",
    "!pip install optuna\n",
    "import optuna\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch.nn.functional as F\n",
    "from csv import writer\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tKLJCHAzjVR"
   },
   "outputs": [],
   "source": [
    "from Scripts.GetData import getDataLoaders, loadData\n",
    "from Scripts.Training import train\n",
    "from Scripts.PlotResults import plotResults\n",
    "from Scripts.SavedParameters import hyperparams\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvozNo5xokaQ"
   },
   "outputs": [],
   "source": [
    "#setting plotting parameters\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(font = \"Times New Roman\")\n",
    "sns.set_context(\"paper\")\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt_kws = {\"rasterized\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tbu-L4lflI7W"
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701703385142,
     "user": {
      "displayName": "Ergys Ã‡okaj",
      "userId": "09876826955139394636"
     },
     "user_tz": -60
    },
    "id": "EF-DUK1HokaR",
    "outputId": "43588840-94a5-42d1-9434-19776ed20a4f"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacase = int(input(\"Which datacase do you want to work with?\\n\"))\n",
    "percentage_train = float(input(\"Which percentage of the dataset do you want to use for training? Choose among 0.1,0.2,0.4,0.8\\n\"))\n",
    "\n",
    "print(f\"\\n\\n Case with percentage_train={percentage_train} and datacase={datacase}\\n\\n\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "class approximate_curve(nn.Module):\n",
    "        def __init__(self, is_res = True, normalize = True, act_name='tanh', nlayers=3, hidden_nodes = 50, output_dim = 204):\n",
    "            super().__init__()\n",
    "\n",
    "            torch.manual_seed(1)\n",
    "            np.random.seed(1)\n",
    "            random.seed(1)\n",
    "            self.act_dict = {\"tanh\":lambda x : torch.tanh(x),\n",
    "                                \"sigmoid\":lambda x : torch.sigmoid(x),\n",
    "                                \"swish\":lambda x : x*torch.sigmoid(x),\n",
    "                                \"relu\":lambda x : torch.relu(x),\n",
    "                                \"lrelu\":lambda x : F.leaky_relu(x)}\n",
    "            self.is_norm = normalize\n",
    "            self.is_res = is_res\n",
    "            self.act = self.act_dict[act_name]\n",
    "            self.nlayers = nlayers\n",
    "            self.first = nn.Linear(8,hidden_nodes)\n",
    "            self.linears = nn.ModuleList([nn.Linear(hidden_nodes,hidden_nodes) for i in range(self.nlayers)])\n",
    "            self.last = nn.Linear(hidden_nodes,output_dim)\n",
    "\n",
    "        def forward(self,x):\n",
    "\n",
    "            if self.is_norm:\n",
    "                x[:,0] = (x[:,0]-1.5)/1.5\n",
    "                x[:,4] = (x[:,4]-1.5)/1.5\n",
    "            x  = self.act(self.first(x))\n",
    "            for i in range(self.nlayers):\n",
    "                if self.is_res: #ResNet\n",
    "                    x = x + self.act(self.linears[i](x))\n",
    "                else: #MLP\n",
    "                    x = self.act(self.linears[i](x))\n",
    "\n",
    "            return self.last(x)\n",
    "        \n",
    "num_nodes, _,_ = loadData(datacase)\n",
    "\n",
    "def define_model(trial):\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "    is_res = False\n",
    "    normalize = True\n",
    "    act_name = \"tanh\"\n",
    "    nlayers = trial.suggest_int(\"n_layers\", 0, 10)\n",
    "    hidden_nodes = trial.suggest_int(\"hidden_nodes\", 10, 1000)\n",
    "\n",
    "    model = approximate_curve(is_res, normalize, act_name, nlayers, hidden_nodes,output_dim=int(4*(num_nodes-2)))\n",
    "    return model\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "    # Generate the model\n",
    "    model = define_model(trial)\n",
    "    model.to(device);\n",
    "\n",
    "    lr = 1e-3\n",
    "    weight_decay = 0\n",
    "    gamma = trial.suggest_float(\"gamma\",0,1e-2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    batch_size = 32\n",
    "    _, _, _, _,x_val,y_val,trainloader,_,valloader = getDataLoaders(batch_size, datacase, percentage_train)\n",
    "\n",
    "    print(\"Current test with :\\n\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    epochs = 300\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = int(0.45*epochs), gamma = 0.1)\n",
    "    \n",
    "    loss = train(model,gamma,criterion,scheduler,optimizer,epochs,trainloader,valloader,device)\n",
    "    print('Loss ',loss.item())\n",
    "    error = 1000\n",
    "\n",
    "    if not torch.isnan(loss):\n",
    "        model.eval();\n",
    "\n",
    "        learned_traj = np.zeros_like(y_val)\n",
    "        \n",
    "        bcs_val = torch.from_numpy(x_val.astype(np.float32)).to(device)\n",
    "        learned_traj = model(bcs_val).detach().cpu().numpy()\n",
    "        error = np.mean((learned_traj-y_val)**2)\n",
    "\n",
    "        print(f\"The error on the validation trajectories is: {error}.\")\n",
    "\n",
    "    #Saving the obtained results\n",
    "    if trial.number == 0:\n",
    "        labels = []\n",
    "        for lab, _ in trial.params.items():\n",
    "            labels.append(str(lab))\n",
    "        labels.append(\"MSE\")\n",
    "        with open(f\"results{int(percentage_train*100)}_Fig2.csv\", \"a\") as f_object:\n",
    "            writer_object = writer(f_object)\n",
    "            writer_object.writerow(labels)\n",
    "            f_object.close()\n",
    "\n",
    "    results = []\n",
    "    for _, value in trial.params.items():\n",
    "        results.append(str(value))\n",
    "\n",
    "    results.append(error)\n",
    "\n",
    "    with open(f\"results{int(percentage_train*100)}_Fig2.csv\", \"a\") as f_object:\n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow(results)\n",
    "        f_object.close()\n",
    "    return error\n",
    "\n",
    "optuna_study = input(\"Do you want to do hyperparameter test? Type yes or no: \")\n",
    "params = {}\n",
    "if optuna_study==\"yes\":\n",
    "    optuna_study = True\n",
    "else:\n",
    "    optuna_study = False\n",
    "if optuna_study:\n",
    "    study = optuna.create_study(direction=\"minimize\",study_name=\"Euler Elastica\")\n",
    "    study.optimize(objective, n_trials=5)\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    params = study.best_params\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "manual_input = False\n",
    "if params=={}:\n",
    "    # We can input them manually by uncommenting the lines below\n",
    "    if manual_input:\n",
    "        print(\"No parameters have been specified. Let's input them:\\n\\n\")\n",
    "        nlayers = int(input(\"How many layers do you want the network to have? \"))\n",
    "        hidden_nodes = int(input(\"How many hidden nodes do you want the network to have? \"))\n",
    "        weight_decay = float(input(\"What weight decay do you want to use? \"))\n",
    "        gamma = float(input(\"What value do you want for gamma? \"))\n",
    "        batch_size = int(input(\"What batch size do you want? \"))\n",
    "\n",
    "        params = {'n_layers': nlayers,\n",
    "                'hidden_nodes': hidden_nodes,\n",
    "                'gamma': gamma}\n",
    "    else:\n",
    "    # or we can use the combinations found by Optuna that yield the best results for the mentioned datacases\n",
    "        params = hyperparams(datacase, percentage_train)\n",
    "print(f'The hyperparameters yelding the best results for this case are: {params}')\n",
    "def define_best_model():\n",
    "    \n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "    normalize = True\n",
    "    act = \"tanh\"\n",
    "    nlayers = params[\"n_layers\"]\n",
    "    hidden_nodes = params[\"hidden_nodes\"]\n",
    "    is_res = False\n",
    "    \n",
    "    print(\"Nodes: \",hidden_nodes)\n",
    "    \n",
    "    model = approximate_curve(is_res, normalize, act, nlayers, hidden_nodes, int(4*(num_nodes-2)))\n",
    "\n",
    "    return model\n",
    "model = define_best_model()\n",
    "model.to(device);\n",
    "\n",
    "TrainMode = input(\"Train Mode True or False? Type 0 for False and 1 for True: \")==\"1\"\n",
    "weight_decay = 0.\n",
    "lr = 1e-3\n",
    "gamma = params[\"gamma\"]\n",
    "nlayers = params[\"n_layers\"]\n",
    "hidden_nodes = params[\"hidden_nodes\"]\n",
    "batch_size = 32\n",
    "epochs = 300\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = int(0.45*epochs), gamma = 0.1)\n",
    "criterion = nn.MSELoss()\n",
    "x_train, y_train, x_test, y_test, x_val, y_val,trainloader, testloader,valloader = getDataLoaders(batch_size, datacase, percentage_train)\n",
    "model.to(device);\n",
    "\n",
    "if TrainMode:\n",
    "    loss = train(model,gamma,criterion,scheduler,optimizer,epochs,trainloader,valloader,device)\n",
    "    if datacase == 1:\n",
    "        torch.save(model.state_dict(), f'TrainedModels/BothEnds{percentage_train}data.pt')\n",
    "    if datacase == 2:\n",
    "        torch.save(model.state_dict(), f'TrainedModels/BothEndsRightEnd{percentage_train}data.pt')\n",
    "else:\n",
    "    if datacase == 1:\n",
    "        pretrained_dict = torch.load(f'TrainedModels/BothEnds{percentage_train}data.pt',map_location=device)\n",
    "    if datacase == 2:\n",
    "        pretrained_dict = torch.load(f'TrainedModels/BothEndsRightEnd{percentage_train}data.pt',map_location=device)\n",
    "    model.load_state_dict(pretrained_dict)\n",
    "model.eval();\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "model.eval();\n",
    "\n",
    "# printing the accuracies and plotting the results\n",
    "plotResults(model, device, x_train, y_train, x_test, y_test, x_val, y_val, num_nodes, datacase, percentage_train, gamma, nlayers, hidden_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "test_bvs = torch.from_numpy(x_test.astype(np.float32))\n",
    "initial_time = time.time()\n",
    "preds = model(test_bvs)\n",
    "final_time = time.time()\n",
    "total_time = final_time-initial_time\n",
    "print(\"Number of trajectories in the test set : \",len(test_bvs))\n",
    "print(\"Total time to predict test trajectories : \",total_time)\n",
    "print(\"Average time to predict test trajectories : \",total_time / len(test_bvs))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
