{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wZmJ-_zvokaO","scrolled":false},"outputs":[],"source":["#importing necessary packages\n","!pip install optuna\n","import optuna\n","import torch\n","import random\n","import torch.nn as nn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import torch.nn.functional as F\n","from csv import writer\n","import seaborn as sns\n","import os\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wnHVY9Hvo4uM"},"outputs":[],"source":["'''# if running with Google Colab, enter the right path from your Drive\n","# otherwise completely comment this cell\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/Othercomputers/My MacBook Pro (1)/LearningEulersElastica/DiscreteNetwork\"'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2tKLJCHAzjVR"},"outputs":[],"source":["from Scripts.GetData import getDataLoaders, loadData\n","from Scripts.Training import train\n","from Scripts.PlotResults import plotResults\n","from Scripts.SavedParameters import hyperparams"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvozNo5xokaQ"},"outputs":[],"source":["#setting plotting parameters\n","sns.set_style(\"darkgrid\")\n","sns.set(font = \"Times New Roman\")\n","sns.set_context(\"paper\")\n","plt.rcParams['mathtext.fontset'] = 'cm'\n","plt.rcParams['font.family'] = 'STIXGeneral'\n","plt_kws = {\"rasterized\": True}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tbu-L4lflI7W"},"outputs":[],"source":["torch.set_default_dtype(torch.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1701703385142,"user":{"displayName":"Ergys Çokaj","userId":"09876826955139394636"},"user_tz":-60},"id":"EF-DUK1HokaR","outputId":"43588840-94a5-42d1-9434-19776ed20a4f"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3752,"status":"ok","timestamp":1701703390791,"user":{"displayName":"Ergys Çokaj","userId":"09876826955139394636"},"user_tz":-60},"id":"b5G_VwcMokaR","outputId":"d0c2d80c-4c55-47bd-f433-daaacd3f6e3e"},"outputs":[],"source":["# both-ends only: datacase == 1\n","# train on both-ends, test on right-end: datacase == 2\n","# train and test on both-ends + right-end: datacase == 3\n","\n","datacase = input(\"Choose datacase \")\n","datacase = int(datacase)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3888,"status":"ok","timestamp":1701703395902,"user":{"displayName":"Ergys Çokaj","userId":"09876826955139394636"},"user_tz":-60},"id":"3ghpwU-eCBA_","outputId":"1d039909-d8d1-44e1-815f-0f8abaa05f8c"},"outputs":[],"source":["if datacase == 1:\n","    percentage_train = input(\"Choose percentage of training data between 90, 40, 20, and 10: \")\n","    percentage_train = int(percentage_train)/100\n","    percentage_train\n","else:\n","    percentage_train = 0.8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrxx1TWUokaS"},"outputs":[],"source":["torch.manual_seed(1)\n","np.random.seed(1)\n","random.seed(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-hJFH5q-okaS"},"outputs":[],"source":["class approximate_curve(nn.Module):\n","        def __init__(self, is_res = True, normalize = True, act_name='tanh', nlayers=3, hidden_nodes = 50, output_dim = 204):\n","          super().__init__()\n","\n","          torch.manual_seed(1)\n","          np.random.seed(1)\n","          random.seed(1)\n","          self.act_dict = {\"tanh\":lambda x : torch.tanh(x),\n","                            \"sigmoid\":lambda x : torch.sigmoid(x),\n","                            \"swish\":lambda x : x*torch.sigmoid(x),\n","                            \"relu\":lambda x : torch.relu(x),\n","                            \"lrelu\":lambda x : F.leaky_relu(x)}\n","          self.is_norm = normalize\n","          self.is_res = is_res\n","          self.act = self.act_dict[act_name]\n","          self.nlayers = nlayers\n","          self.first = nn.Linear(8,hidden_nodes)\n","          self.linears = nn.ModuleList([nn.Linear(hidden_nodes,hidden_nodes) for i in range(self.nlayers)])\n","          self.last = nn.Linear(hidden_nodes,output_dim)\n","\n","        def forward(self,x):\n","\n","            if self.is_norm:\n","                x[:,0] = (x[:,0]-1.5)/1.5\n","                x[:,4] = (x[:,4]-1.5)/1.5\n","            x  = self.act(self.first(x))\n","            for i in range(self.nlayers):\n","                if self.is_res: #ResNet\n","                    x = x + self.act(self.linears[i](x))\n","                else: #MLP\n","                    x = self.act(self.linears[i](x))\n","\n","            return self.last(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbJ6juc9okaT"},"outputs":[],"source":["num_nodes, _,_ = loadData(datacase)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5CienmkokaT"},"outputs":[],"source":["def define_model(trial):\n","    torch.manual_seed(1)\n","    np.random.seed(1)\n","    random.seed(1)\n","    is_res = False #trial.suggest_categorical(\"is_res\",[True,False])\n","    normalize = True #trial.suggest_categorical(\"normalize\",[True,False])\n","    act_name = \"tanh\" #trial.suggest_categorical(\"act\",['tanh','swish','sigmoid','relu','lrelu'])\n","    nlayers = trial.suggest_int(\"n_layers\", 0, 4)\n","    hidden_nodes = trial.suggest_int(\"hidden_nodes\", 32, 1024)\n","\n","    model = approximate_curve(is_res, normalize, act_name, nlayers, hidden_nodes,output_dim=int(4*(num_nodes-2)))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e48-KIkBokaT"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IrM5LgqnPioH"},"outputs":[],"source":["def objective(trial):\n","\n","    torch.manual_seed(1)\n","    np.random.seed(1)\n","    random.seed(1)\n","\n","    # Generate the model\n","    model = define_model(trial)\n","    model.to(device);\n","\n","    lr = 1e-3 #trial.suggest_float(\"lr\", 1e-4 , 1e-1, log=True)\n","    weight_decay = 0 #trial.suggest_float(\"weight_decay\",1e-7,5e-4,log=True)\n","    gamma = trial.suggest_float(\"gamma\",0,1e-2) #smoothing regularization\n","    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n","\n","    criterion = nn.MSELoss()\n","\n","    batch_size = 32 #trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n","    _, _, _, _, x_val,y_val,trainloader,_,valloader = getDataLoaders(batch_size, datacase, percentage_train)\n","\n","    print(\"Current test with :\\n\\n\")\n","    for key, value in trial.params.items():\n","      print(\"    {}: {}\".format(key, value))\n","    print(\"\\n\\n\")\n","\n","    epochs = 300\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = epochs//3, gamma = 0.1)\n","    loss = train(model,gamma,criterion,scheduler,optimizer,epochs,trainloader,valloader,device)\n","    print('Loss ',loss.item())\n","    error = 1000\n","\n","    if not torch.isnan(loss):\n","        model.eval();\n","\n","        learned_traj = np.zeros_like(y_val)\n","\n","        for i in range(len(x_val)):\n","            bcsol =  torch.from_numpy(x_val[i:i+1].astype(np.float32)).to(device)\n","            learned_traj[i] = model(bcsol)[0].detach().cpu().numpy()\n","        error = np.mean((learned_traj - y_val)**2)\n","        print(learned_traj.shape, y_val.shape)\n","        print(f\"The error on the validation trajectories is: {error}.\")\n","\n","\n","    datanames = [\"both_ends\", \"both_ends_right_end\"]\n","    if datacase == 1:\n","        dataname = datanames[0]\n","    if datacase == 3:\n","        dataname = datanames[1]\n","\n","    #Saving the obtained results\n","    if trial.number == 0:\n","        labels = []\n","        for lab, _ in trial.params.items():\n","            labels.append(str(lab))\n","        labels.append(\"MSE\")\n","        with open(\"SavedResults.csv\", \"a\") as f_object:\n","            writer_object = writer(f_object)\n","            writer_object.writerow(labels)\n","            writer_object.writerow(f\"\\n\\n Datacase: {dataname}, Percentage of training data: {percentage_train}\")\n","            f_object.close()\n","\n","    results = []\n","    for _, value in trial.params.items():\n","        results.append(str(value))\n","\n","    results.append(error)\n","\n","    with open(\"SavedResults.csv\", \"a\") as f_object:\n","        writer_object = writer(f_object)\n","        writer_object.writerow(results)\n","        f_object.close()\n","    return error"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4503,"status":"ok","timestamp":1701703410209,"user":{"displayName":"Ergys Çokaj","userId":"09876826955139394636"},"user_tz":-60},"id":"5OWWjETyokaU","outputId":"f4e8d33c-884e-4398-e83c-f2c572a7f6b4","scrolled":false},"outputs":[],"source":["optuna_study = input(\"Do you want to do hyperparameter test? Type yes or no: \")\n","params = {}\n","if optuna_study==\"yes\":\n","    optuna_study = True\n","else:\n","    optuna_study = False\n","if optuna_study:\n","    study = optuna.create_study(direction=\"minimize\",study_name=\"Euler Elastica\")\n","    study.optimize(objective, n_trials=300)\n","    print(\"Study statistics: \")\n","    print(\"Number of finished trials: \", len(study.trials))\n","    params = study.best_params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qtteYdRWokaU"},"outputs":[],"source":["torch.manual_seed(1)\n","np.random.seed(1)\n","random.seed(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuemAi_YokaU"},"outputs":[],"source":["manual_input = False\n","if params=={}:\n","    # We can input them manually by uncommenting the lines below\n","    if manual_input:\n","        print(\"No parameters have been specified. Let's input them:\\n\\n\")\n","        is_res = input(\"Is_res True or False? \")==\"True\"\n","        normalize = input(\"Normalize is True or False? \")==\"True\"\n","        act = input(\"What activation function to use? Choose among 'sin', 'sigmoid', 'swish', 'tanh' \")\n","        nlayers = int(input(\"How many layers do you want the network to have? \"))\n","        hidden_nodes = int(input(\"How many hidden nodes do you want the network to have? \"))\n","        lr = float(input(\"What learning rate do you want to use? \"))\n","        weight_decay = float(input(\"What weight decay do you want to use? \"))\n","        gamma = float(input(\"What value do you want for gamma? \"))\n","        batch_size = int(input(\"What batch size do you want? \"))\n","\n","        params = {'is_res': is_res,\n","                'normalize': normalize,\n","                'act': act,\n","                'n_layers': nlayers,\n","                'hidden_nodes': hidden_nodes,\n","                'lr': lr,\n","                'weight_decay': weight_decay,\n","                'gamma': gamma,\n","                'batch_size': batch_size}\n","    else:\n","    # or we can use the combinations found by Optuna that yield the best results for the mentioned datacases\n","        params = hyperparams(datacase, percentage_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1701703414729,"user":{"displayName":"Ergys Çokaj","userId":"09876826955139394636"},"user_tz":-60},"id":"6XcrsDPrCBBD","outputId":"a1645f5a-20ac-469b-e46b-188b33f5b1cc"},"outputs":[],"source":["print(f'The hyperparameters yelding the best results for this case are: {params}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YTlIfrLokaU"},"outputs":[],"source":["def define_best_model():\n","    torch.manual_seed(1)\n","    np.random.seed(1)\n","    random.seed(1)\n","\n","    normalize = True #params[\"normalize\"]\n","    act = \"tanh\" #params[\"act\"]\n","    nlayers = params[\"n_layers\"]\n","    hidden_nodes = params[\"hidden_nodes\"]\n","    is_res = False #params[\"is_res\"]\n","\n","    model = approximate_curve(is_res, normalize, act, nlayers, hidden_nodes, int(4*(num_nodes-2)))\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gsBjKY3xokaV"},"outputs":[],"source":["model = define_best_model()\n","model.to(device);"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5485,"status":"ok","timestamp":1701703425773,"user":{"displayName":"Ergys Çokaj","userId":"09876826955139394636"},"user_tz":-60},"id":"QhfXWVPOCBBE","outputId":"017d52d7-8d14-48b7-815d-62b142989c0c"},"outputs":[],"source":["TrainMode = input(\"Train Mode True or False? Type 0 for False and 1 for True: \")\n","TrainMode = int(TrainMode)\n","if TrainMode == 0:\n","    TrainMode = False\n","else:\n","    TrainMode = True\n","TrainMode"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2EVVJCtokaV"},"outputs":[],"source":["weight_decay = 0. #params[\"weight_decay\"]\n","lr = 1e-3 #params[\"lr\"]\n","gamma = params[\"gamma\"]\n","batch_size = 32 #params[\"batch_size\"]\n","epochs = 300\n","optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = epochs//3, gamma = 0.1)\n","criterion = nn.MSELoss()\n","x_train, y_train, x_test, y_test, x_val, y_val,trainloader, testloader,valloader = getDataLoaders(batch_size, datacase, percentage_train)\n","model.to(device);\n","\n","if TrainMode:\n","    loss = train(model,gamma,criterion,scheduler,optimizer,epochs,trainloader,valloader,device)\n","    if datacase == 1:\n","        if percentage_train == 0.9:\n","            torch.save(model.state_dict(), 'TrainedModels/BothEnds0.9data.pt')\n","        elif percentage_train == 0.4:\n","            torch.save(model.state_dict(), 'TrainedModels/BothEnds0.4data.pt')\n","        elif percentage_train == 0.2:\n","            torch.save(model.state_dict(), 'TrainedModels/BothEnds0.2data.pt')\n","        else:\n","            torch.save(model.state_dict(), 'TrainedModels/BothEnds0.1data.pt')\n","    if datacase == 2:\n","        torch.save(model.state_dict(), 'TrainedModels/BothEndsExtrapolation0.9data.pt')\n","    if datacase == 3:\n","        torch.save(model.state_dict(), 'TrainedModels/BothEndsRightEnd0.9data.pt')\n","else:\n","    if datacase == 1:\n","        if percentage_train == 0.9:\n","            pretrained_dict = torch.load(f'TrainedModels/BothEnds0.9data.pt',map_location=device)\n","        elif percentage_train == 0.4:\n","            pretrained_dict = torch.load(f'TrainedModels/BothEnds0.4data.pt',map_location=device)\n","        elif percentage_train == 0.2:\n","            pretrained_dict = torch.load(f'TrainedModels/BothEnds0.2data.pt',map_location=device)\n","        else:\n","            pretrained_dict = torch.load(f'TrainedModels/BothEnds0.1data.pt',map_location=device)\n","    if datacase == 2:\n","        pretrained_dict = torch.load(f'TrainedModels/BothEndsExtrapolation0.9data.pt',map_location=device)\n","    if datacase == 3:\n","        pretrained_dict = torch.load(f'TrainedModels/BothEndsRightEnd0.9data.pt',map_location=device)\n","    model.load_state_dict(pretrained_dict)\n","model.eval();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYG2b2J0okaV"},"outputs":[],"source":["torch.manual_seed(1)\n","np.random.seed(1)\n","random.seed(1)\n","\n","model.eval();"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plotResults(model, device, x_train, y_train, x_test, y_test, num_nodes, datacase, percentage_train):\n","\n","    train_bcs = torch.from_numpy(x_train.astype(np.float32)).to(device)\n","    test_bcs = torch.from_numpy(x_test.astype(np.float32)).to(device)\n","\n","    pred_train = np.concatenate((x_train[:, :4], model(train_bcs).detach().cpu().numpy(), x_train[:, -4:]), axis = 1)\n","    pred_test = np.concatenate((x_test[:, :4], model(test_bcs).detach().cpu().numpy(), x_test[:, -4:]), axis = 1)\n","\n","    true_train = np.concatenate((x_train[:, :4], y_train, x_train[:, -4:]), axis = 1)\n","    true_test = np.concatenate((x_test[:, :4], y_test, x_test[:, -4:]), axis = 1)\n","\n","    pred = np.concatenate((pred_train[:,4:-4], pred_test[:,4:-4]), axis = 0)\n","    true = np.concatenate((true_train[:,4:-4], true_test[:,4:-4]), axis = 0)\n","    error_all = np.mean((pred - true)**2)\n","    error_training = np.mean((pred_train[:,4:-4] - true_train[:,4:-4])**2)\n","    error_testing = np.mean((pred_test[:,4:-4] - true_test[:,4:-4])**2)\n","\n","    print(f\"\\n Error over training trajectories: {error_training}, \\n Error over test trajectories: {error_testing}, \\n Error over all trajectories: {error_all}.\")\n","\n","    c, d = pred_test.shape\n","\n","    norms_q = np.zeros((len(pred_test), num_nodes))\n","    mean_q = np.zeros(num_nodes)\n","    norms_qp = np.zeros((len(pred_test), num_nodes))\n","    mean_qp = np.zeros(num_nodes)\n","    for i in range(len(pred_test)):\n","        for j in range(num_nodes):\n","            norms_q[i, j] = np.linalg.norm(pred_test[i, 4*j:4*j+2] - true_test[i,4*j:4*j+2])\n","            mean_q[j] = np.mean(norms_q[:, j])\n","            norms_qp[i, j] = np.linalg.norm(pred_test[i, 4*j+2:4*j+4] - true_test[i,4*j+2:4*j+4])\n","            mean_qp[j] = np.mean(norms_qp[:, j])\n","                \n","    if datacase == 1:\n","        if percentage_train == 0.8:\n","            fig1 = plt.figure(figsize = ((20, 15)))\n","            for i in range(1):\n","                plt.plot(true_test[i, np.arange(0, d, 4)], true_test[i, np.arange(1, d, 4)], '-', linewidth = 3, color = 'k', label = 'True')\n","                plt.plot(pred_test[i, np.arange(0, d, 4)], pred_test[i, np.arange(1, d, 4)], '--d', markersize = 5, linewidth = 1.8, color = 'r', label = 'Predicted')\n","            for i in np.arange(1,c,11): #remove \",11\" from np.arange if you want to plot all test trajectories\n","                plt.plot(true_test[i, np.arange(0, d, 4)], true_test[i, np.arange(1, d, 4)], '-', linewidth = 3, color = 'k')\n","                plt.plot(pred_test[i, np.arange(0, d, 4)], pred_test[i, np.arange(1, d, 4)], '--d', markersize = 5, linewidth = 1.8, color = 'r')\n","            plt.xlabel(r\"$q_x$\", fontsize = \"45\")\n","            plt.ylabel(r\"$q_y$\", fontsize = \"45\")\n","            plt.tick_params(labelsize = \"45\")\n","            plt.legend(fontsize = \"45\", loc = 'best')\n","            plt.title(r\"Comparison over test trajectories $(q_x, q_y)$\", fontsize = \"45\")\n","            plt.savefig(\"q.pdf\")\n","            plt.show()\n","\n","            fig2 = plt.figure(figsize = ((20, 15)))\n","            for i in range(1):\n","                plt.scatter(true_test[i, np.arange(2, d, 4)], true_test[i, np.arange(3, d, 4)], color = 'k', s = 90, label = 'True')\n","                plt.scatter(pred_test[i, np.arange(2, d, 4)], pred_test[i, np.arange(3, d, 4)], color = 'r', s = 30, label = 'Predicted')\n","            for i in np.arange(1,c,11): #remove \",11\" from np.arange if you want to plot all test trajectories\n","                plt.scatter(true_test[i, np.arange(2, d, 4)], true_test[i, np.arange(3, d, 4)], color = 'k', s = 90)\n","                plt.scatter(pred_test[i, np.arange(2, d, 4)], pred_test[i, np.arange(3, d, 4)], color = 'r', s = 30)\n","            plt.xlabel(r\"$q^{\\prime}_x$\", fontsize = \"45\")\n","            plt.ylabel(r\"$q^{\\prime}_y$\", fontsize = \"45\")\n","            plt.tick_params(labelsize = \"45\")\n","            plt.axis('equal')\n","            plt.title(r\"Comparison over test trajectories $(q^{\\prime}_x, q^{\\prime}_y)$\", fontsize = \"45\")\n","            plt.legend(fontsize = \"45\", loc = 'center')\n","            plt.savefig(\"qprime.pdf\")\n","            plt.show()\n","\n","            fig3 = plt.figure(figsize = ((20, 15)))\n","            plt.plot(np.linspace(0, 50, 51), mean_q, '-d', linewidth = 2, color = 'k', label = r\"Error on $(q_x, q_y)$ \")\n","            plt.plot(np.linspace(0, 50, 51), mean_qp, '-d', linewidth = 2, color = 'r', label = r\"Error on $(q^{\\prime}_x, q^{\\prime}_y)$\")\n","            plt.xlabel(r\"node $k$\", fontsize = \"45\")\n","            plt.ylabel(r\"Average norm of error\", fontsize = \"45\")\n","            plt.tick_params(labelsize = \"45\")\n","            plt.title(r\"Mean error over test trajectories\", fontsize = \"45\")\n","            plt.legend(fontsize = \"45\", loc = 'best')\n","            plt.savefig(\"error.pdf\")\n","            plt.show()\n","\n","    \n","    if datacase == 3:\n","        fig1 = plt.figure(figsize = ((20, 15)))\n","        for i in range(1):\n","            plt.plot(true_test[i, np.arange(0, d, 4)], true_test[i, np.arange(1, d, 4)], '-', linewidth = 3, color = 'k', label = 'True')\n","            plt.plot(pred_test[i, np.arange(0, d, 4)], pred_test[i, np.arange(1, d, 4)], '--d', markersize = 5, linewidth = 1.8, color = 'r', label = 'Predicted')\n","        for i in np.arange(2,c,22): #remove \",22\" from np.arange if you want to plot all test trajectories\n","            plt.plot(true_test[i, np.arange(0, d, 4)], true_test[i, np.arange(1, d, 4)], '-', linewidth = 3, color = 'k')\n","            plt.plot(pred_test[i, np.arange(0, d, 4)], pred_test[i, np.arange(1, d, 4)], '--d', markersize = 5, linewidth = 1.8, color = 'r')\n","        plt.xlabel(r\"$q_x$\", fontsize = \"45\")\n","        plt.ylabel(r\"$q_y$\", fontsize = \"45\")\n","        plt.tick_params(labelsize = \"45\")\n","        plt.legend(fontsize = \"45\", loc = 'best')\n","        plt.title(r\"Comparison over test trajectories $(q_x, q_y)$\", fontsize = \"45\")\n","        plt.show()\n","\n","        fig2 = plt.figure(figsize = ((20, 15)))\n","        for i in range(1):\n","            plt.scatter(true_test[i, np.arange(2, d, 4)], true_test[i, np.arange(3, d, 4)], color = 'k', s = 90, label = 'True')\n","            plt.scatter(pred_test[i, np.arange(2, d, 4)], pred_test[i, np.arange(3, d, 4)], color = 'r', s = 30, label = 'Predicted')\n","        for i in np.arange(2,c,22): #remove \",22\" from np.arange if you want to plot all test trajectories\n","            plt.scatter(true_test[i, np.arange(2, d, 4)], true_test[i, np.arange(3, d, 4)], color = 'k', s = 90)\n","            plt.scatter(pred_test[i, np.arange(2, d, 4)], pred_test[i, np.arange(3, d, 4)], color = 'r', s = 30)\n","        plt.xlabel(r\"$q^{\\prime}_x$\", fontsize = \"45\")\n","        plt.ylabel(r\"$q^{\\prime}_y$\", fontsize = \"45\")\n","        plt.tick_params(labelsize = \"45\")\n","        plt.axis('equal')\n","        plt.title(r\"Comparison over test trajectories $(q^{\\prime}_x, q^{\\prime}_y)$\", fontsize = \"45\")\n","        plt.legend(fontsize = \"45\", loc = 'center')\n","        plt.show()\n","\n","        fig3 = plt.figure(figsize = ((20, 15)))\n","        plt.plot(np.linspace(0, 50, 51), mean_q, '-d', linewidth = 2, color = 'k', label = r\"Error on $(q_x, q_y)$ \")\n","        plt.plot(np.linspace(0, 50, 51), mean_qp, '-d', linewidth = 2, color = 'r', label = r\"Error on $(q^{\\prime}_x, q^{\\prime}_y)$\")\n","        plt.xlabel(r\"node $k$\", fontsize = \"45\")\n","        plt.ylabel(r\"Average norm of error\", fontsize = \"45\")\n","        plt.tick_params(labelsize = \"45\")\n","        plt.title(r\"Mean error over test trajectories\", fontsize = \"45\")\n","        plt.legend(fontsize = \"45\", loc = 'best')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3635,"status":"ok","timestamp":1701703433202,"user":{"displayName":"Ergys Çokaj","userId":"09876826955139394636"},"user_tz":-60},"id":"Utj-lB-oCBBG","outputId":"e15cf5d9-7fe1-4e65-f521-d673363ad9d8"},"outputs":[],"source":["# printing the accuracies and plotting the results\n","plotResults(model, device, x_train, y_train, x_test, y_test, num_nodes, datacase, percentage_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
